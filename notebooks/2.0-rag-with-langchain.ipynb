{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build a RAG Agent with LangChain\n",
        "\n",
        "This notebook demonstrates how to build a Retrieval Augmented Generation (RAG) application with LangChain.\n",
        "\n",
        "**What is RAG?**\n",
        "RAG is a technique that enables LLMs to answer questions about specific source information by:\n",
        "1. **Indexing**: Creating a searchable index from your data sources\n",
        "2. **Retrieval and Generation**: Retrieving relevant context and using it to generate answers\n",
        "\n",
        "We'll cover:\n",
        "- **Indexing Pipeline**: Loading, splitting, and storing documents\n",
        "- **RAG Agents**: Using agents with retrieval tools for flexible querying\n",
        "- **RAG Chains**: Two-step chains for fast, simple queries\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required packages and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install -qU langchain langchain-text-splitters langchain-community bs4 langchain-openai langchain-chroma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 1: Indexing\n",
        "\n",
        "The indexing pipeline prepares your data for retrieval. This typically happens in a separate process before querying.\n",
        "\n",
        "## 1.1 Loading Documents\n",
        "\n",
        "We'll use the LLM Powered Autonomous Agents blog post by Lilian Weng as our data source.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 document(s)\n",
            "First document length: 22843 characters\n",
            "\n",
            "First 500 characters:\n",
            "Skip to main contentSkip to footerResearchEconomic FuturesCommitmentsLearnNewsTry ClaudeEngineering at AnthropicWriting effective tools for agents — with agentsPublished Sep 11, 2025Agents are only as effective as the tools we give them. We share how to write high-quality tools and evaluations, and how you can boost performance by using Claude to optimize its tools for itself.The Model Context Protocol (MCP) can empower LLM agents with potentially hundreds of tools to solve real-world tasks. But...\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Load the blog post content without relying on bs4 SoupStrainer that may not match the site's structure.\n",
        "# Instead, use the default loader behavior and rely on the loader to extract all the text from the page.\n",
        "urls = [\"https://www.anthropic.com/engineering/writing-tools-for-agents\",\n",
        "        \"https://www.anthropic.com/engineering/building-effective-agents\"]\n",
        "\n",
        "loader = WebBaseLoader(urls)\n",
        "docs = loader.load()\n",
        "\n",
        "if not docs:\n",
        "    raise ValueError(\"No documents were loaded. The page may be protected by anti-bot measures, or the loader could not parse the content.\")\n",
        "\n",
        "print(f\"Loaded {len(docs)} document(s)\")\n",
        "print(f\"First document length: {len(docs[0].page_content)} characters\")\n",
        "print(f\"\\nFirst 500 characters:\\n{docs[0].page_content[:500]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Splitting Documents\n",
        "\n",
        "We need to split the documents into smaller chunks that can be efficiently retrieved. The `RecursiveCharacterTextSplitter` is a good default choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split into 54 chunks\n",
            "\n",
            "First chunk (length: 989):\n",
            "Skip to main contentSkip to footerResearchEconomic FuturesCommitmentsLearnNewsTry ClaudeEngineering at AnthropicWriting effective tools for agents — with agentsPublished Sep 11, 2025Agents are only as effective as the tools we give them. We share how to write high-quality tools and evaluations, and ...\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Split into {len(all_splits)} chunks\")\n",
        "print(f\"\\nFirst chunk (length: {len(all_splits[0].page_content)}):\")\n",
        "print(all_splits[0].page_content[:300] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Storing Documents in a Vector Store\n",
        "\n",
        "We'll use Chroma as our vector store. The documents are embedded and stored for semantic search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store created with 54 documents\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Create embeddings and vector store\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = Chroma.from_documents(\n",
        "    documents=all_splits,\n",
        "    embedding=embeddings,\n",
        "    collection_name=\"rag-tutorial\",\n",
        "    persist_directory=\"./chroma-db\"\n",
        ")\n",
        "\n",
        "print(f\"Vector store created with {len(all_splits)} documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 2: Retrieval and Generation\n",
        "\n",
        "Now that we've indexed our data, we can build RAG applications. We'll demonstrate two approaches:\n",
        "\n",
        "1. **RAG Agents**: Flexible agents that decide when to search\n",
        "2. **RAG Chains**: Fast two-step chains that always search\n",
        "\n",
        "## 2.1 RAG Agents\n",
        "\n",
        "RAG agents use tools to retrieve context. The agent decides when to call the retrieval tool, allowing for:\n",
        "- Multiple searches in support of a single query\n",
        "- Contextual search queries\n",
        "- Skipping searches for simple queries\n",
        "\n",
        "Let's create a retrieval tool and build an agent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_core.tools import tool\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# Initialize the model\n",
        "model = init_chat_model(\"openai:gpt-4o-mini\")\n",
        "\n",
        "# Create a retrieval tool\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve_context(query: str):\n",
        "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs\n",
        "\n",
        "tools = [retrieve_context]\n",
        "\n",
        "# Create the agent with custom instructions\n",
        "prompt = (\n",
        "    \"You have access to a tool that retrieves context from a blog post. \"\n",
        "    \"Use the tool to help answer user queries.\"\n",
        ")\n",
        "agent = create_agent(model, tools, system_prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the RAG Agent\n",
        "\n",
        "Let's test with a simple query:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the challenge of writing tools for agents?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve_context (call_Ckk5yhsjtV4ltgJL3a7fY6fN)\n",
            " Call ID: call_Ckk5yhsjtV4ltgJL3a7fY6fN\n",
            "  Args:\n",
            "    query: challenge of writing tools for agents\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve_context\n",
            "\n",
            "Source: {'source': 'https://www.anthropic.com/engineering/writing-tools-for-agents', 'language': 'en', 'title': 'Writing effective tools for AI agents—using AI agents \\\\ Anthropic', 'description': 'Writing effective tools for AI agents—using AI agents'}\n",
            "Content: performance improvements even beyond what we achieved with \"expert\" tool implementations—whether those tools were manually written by our researchers or generated by Claude itself.In the next section, we’ll share some of what we learned from this process.Principles for writing effective toolsIn this section, we distill our learnings into a few guiding principles for writing effective tools.Choosing the right tools for agentsMore tools don’t always lead to better outcomes. A common error we’ve observed is tools that merely wrap existing software functionality or API endpoints—whether or not the tools are appropriate for agents. This is because agents have distinct “affordances” to traditional software—that is, they have different ways of perceiving the potential actions they can take with those toolsLLM agents have limited \"context\" (that is, there are limits to how much information they can process at once), whereas computer memory is cheap and abundant. Consider the task of searching\n",
            "\n",
            "Source: {'source': 'https://www.anthropic.com/engineering/writing-tools-for-agents', 'language': 'en', 'description': 'Writing effective tools for AI agents—using AI agents', 'title': 'Writing effective tools for AI agents—using AI agents \\\\ Anthropic'}\n",
            "Content: performance improvements even beyond what we achieved with \"expert\" tool implementations—whether those tools were manually written by our researchers or generated by Claude itself.In the next section, we’ll share some of what we learned from this process.Principles for writing effective toolsIn this section, we distill our learnings into a few guiding principles for writing effective tools.Choosing the right tools for agentsMore tools don’t always lead to better outcomes. A common error we’ve observed is tools that merely wrap existing software functionality or API endpoints—whether or not the tools are appropriate for agents. This is because agents have distinct “affordances” to traditional software—that is, they have different ways of perceiving the potential actions they can take with those toolsLLM agents have limited \"context\" (that is, there are limits to how much information they can process at once), whereas computer memory is cheap and abundant. Consider the task of searching\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The challenge of writing tools for agents, particularly AI agents, involves several key considerations:\n",
            "\n",
            "1. **Selecting Appropriate Tools**: It is essential to choose tools that align with the unique capabilities and needs of agents. Merely wrapping existing software functionalities or API endpoints often does not yield effective outcomes.\n",
            "\n",
            "2. **Understanding Agent Affordances**: Agents perceive potential actions differently than traditional software. This requires a thoughtful approach to how tools interact with them.\n",
            "\n",
            "3. **Context Limitations**: Large Language Model (LLM) agents have restricted context, meaning they can only process a limited amount of information simultaneously. This contrasts with traditional computing, where memory resources tend to be more abundant. Designing tools that work effectively within these constraints is a significant challenge.\n",
            "\n",
            "These factors highlight the need for carefully crafted tools that leverage the strengths and acknowledge the limitations of AI agents.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the challenge of writing tools for agents?\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi-Step Retrieval\n",
        "\n",
        "The agent can perform multiple searches to answer complex questions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How to build effective agents?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve_context (call_EplnVMtI49JZUTB7k9rCpVNW)\n",
            " Call ID: call_EplnVMtI49JZUTB7k9rCpVNW\n",
            "  Args:\n",
            "    query: build effective agents\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve_context\n",
            "\n",
            "Source: {'title': 'Building Effective AI Agents \\\\ Anthropic', 'language': 'en', 'description': 'Discover how Anthropic approaches the development of reliable AI agents. Learn about our research on agent capabilities, safety considerations, and technical framework for building trustworthy AI.', 'source': 'https://www.anthropic.com/engineering/building-effective-agents'}\n",
            "Content: can help you get started quickly, but don't hesitate to reduce abstraction layers and build with basic components as you move to production. By following these principles, you can create agents that are not only powerful but also reliable, maintainable, and trusted by their users.AcknowledgementsWritten by Erik Schluntz and Barry Zhang. This work draws upon our experiences building agents at Anthropic and the valuable insights shared by our customers, for which we're deeply grateful.Appendix 1: Agents in practiceOur work with customers has revealed two particularly promising applications for AI agents that demonstrate the practical value of the patterns discussed above. Both applications illustrate how agents add the most value for tasks that require both conversation and action, have clear success criteria, enable feedback loops, and integrate meaningful human oversight.A. Customer supportCustomer support combines familiar chatbot interfaces with enhanced capabilities through tool\n",
            "\n",
            "Source: {'title': 'Building Effective AI Agents \\\\ Anthropic', 'language': 'en', 'description': 'Discover how Anthropic approaches the development of reliable AI agents. Learn about our research on agent capabilities, safety considerations, and technical framework for building trustworthy AI.', 'source': 'https://www.anthropic.com/engineering/building-effective-agents'}\n",
            "Content: Skip to main contentSkip to footerResearchEconomic FuturesCommitmentsLearnNewsTry ClaudeEngineering at AnthropicBuilding effective agentsPublished Dec 19, 2024We've worked with dozens of teams building LLM agents across industries. Consistently, the most successful implementations use simple, composable patterns rather than complex frameworks. Over the past year, we've worked with dozens of teams building large language model (LLM) agents across industries. Consistently, the most successful implementations weren't using complex frameworks or specialized libraries. Instead, they were building with simple, composable patterns.In this post, we share what we’ve learned from working with our customers and building agents ourselves, and give practical advice for developers on building effective agents.What are agents?\"Agent\" can be defined in several ways. Some customers define agents as fully autonomous systems that operate independently over extended periods, using various tools to\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "To build effective agents, consider the guidance provided by Anthropic, which emphasizes several key principles:\n",
            "\n",
            "1. **Use Simple, Composable Patterns**: Rather than complex frameworks, success often comes from implementing straightforward, modular designs. This approach allows for better maintainability and adaptability.\n",
            "\n",
            "2. **Focus on Core Capabilities**: Start with foundational features and gradually enhance the agent's functionality as required. This helps reduce unnecessary complexity and allows for easier troubleshooting.\n",
            "\n",
            "3. **Real-World Applications**: Identify practical use cases where agents can add significant value. For example, tasks that involve both conversation and action, have clear success criteria, and allow for meaningful human oversight often deliver the best results. Customer support is a prime example where these attributes are evident.\n",
            "\n",
            "4. **Feedback Loops and Human Oversight**: Implement systems that enable feedback loops to improve the agent's performance over time, while integrating human oversight for safety and reliability.\n",
            "\n",
            "By following these principles, you can create agents that are powerful, reliable, and trusted by users. For more detailed insights, you can explore further in the complete guidelines by Anthropic [here](https://www.anthropic.com/engineering/building-effective-agents).\n"
          ]
        }
      ],
      "source": [
        "query = (\n",
        "    \"How to build effective agents?\"\n",
        ")\n",
        "\n",
        "for event in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Benefits of RAG Agents:**\n",
        "- ✅ Search only when needed\n",
        "- ✅ Contextual search queries\n",
        "- ✅ Multiple searches allowed\n",
        "\n",
        "**Trade-offs:**\n",
        "- ⚠️ Two inference calls (one for tool call, one for response)\n",
        "- ⚠️ Reduced control (LLM may skip or add unnecessary searches)\n",
        "\n",
        "---\n",
        "\n",
        "## 2.2 RAG Chains\n",
        "\n",
        "RAG chains use a two-step approach:\n",
        "1. Always run a search (using the user query)\n",
        "2. Incorporate results as context in a single LLM call\n",
        "\n",
        "This results in **one inference call per query**, trading flexibility for speed.\n",
        "\n",
        "### Using Dynamic Prompts Middleware\n",
        "\n",
        "We can implement a RAG chain using middleware to inject context:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
        "\n",
        "@dynamic_prompt\n",
        "def prompt_with_context(request: ModelRequest) -> str:\n",
        "    \"\"\"Inject context into state messages.\"\"\"\n",
        "    last_query = request.state[\"messages\"][-1].text\n",
        "    retrieved_docs = vector_store.similarity_search(last_query)\n",
        "\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "\n",
        "    system_message = (\n",
        "        \"You are a helpful assistant. Use the following context in your response:\"\n",
        "        f\"\\n\\n{docs_content}\"\n",
        "    )\n",
        "\n",
        "    return system_message\n",
        "\n",
        "# Create agent with middleware (no tools needed)\n",
        "rag_chain = create_agent(model, tools=[], middleware=[prompt_with_context])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is task decomposition?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Task decomposition is the process of breaking down a complex task into smaller, more manageable subtasks or components. This approach allows for easier handling, understanding, and execution of the overall task. By dividing a task into simpler parts, each subtask can be tackled individually, making it less overwhelming and more organized. \n",
            "\n",
            "In the context of agents or artificial intelligence, task decomposition can help improve the accuracy and efficiency of executing tasks by allowing agents to focus on one subtask at a time, potentially reducing errors and improving outcomes. Each subtask can also be handled by different tools or processes, enhancing flexibility and operability. The idea is to create a structured approach that leads to clearer paths for problem-solving and decision-making in complex scenarios.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is task decomposition?\"\n",
        "\n",
        "for step in rag_chain.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Returning Source Documents\n",
        "\n",
        "If you need access to the source documents (e.g., for citations), you can use middleware to store them in the state:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "from langchain_core.documents import Document\n",
        "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
        "\n",
        "\n",
        "class State(AgentState):\n",
        "    context: list[Document]\n",
        "\n",
        "\n",
        "class RetrieveDocumentsMiddleware(AgentMiddleware[State]):\n",
        "    state_schema = State\n",
        "\n",
        "    def before_model(self, state: AgentState) -> dict[str, Any] | None:\n",
        "        last_message = state[\"messages\"][-1]\n",
        "        retrieved_docs = vector_store.similarity_search(last_message.text)\n",
        "\n",
        "        docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "\n",
        "        augmented_message_content = (\n",
        "            f\"{last_message.text}\\n\\n\"\n",
        "            \"Use the following context to answer the query:\\n\"\n",
        "            f\"{docs_content}\"\n",
        "        )\n",
        "        return {\n",
        "            \"messages\": [last_message.model_copy(update={\"content\": augmented_message_content})],\n",
        "            \"context\": retrieved_docs,\n",
        "        }\n",
        "\n",
        "\n",
        "rag_chain_with_sources = create_agent(\n",
        "    model,\n",
        "    tools=[],\n",
        "    middleware=[RetrieveDocumentsMiddleware()],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response:\n",
            "Task decomposition is the process of breaking down a complex task into smaller, more manageable subtasks. This approach helps streamline workflows by assigning specific, well-defined tasks to agents or tools, reducing the likelihood of errors and improving efficiency. In the context provided, task decomposition serves several purposes:\n",
            "\n",
            "1. **Reducing Complexity**: By segmenting a larger task into smaller components, agents can focus on individual parts, which helps mitigate the risk of making mistakes. This is particularly important because agents may miscall tools or parameters when faced with an extensive, intricate task.\n",
            "\n",
            "2. **Improving Tool Utilization**: When tasks are well-defined and correspond to specific tools that match these subdivisions, agents can better select and utilize the appropriate tools, thereby enhancing the effectiveness of tool calls. This means that agents don’t have to manage an overwhelming number of tool descriptions and can instead leverage relevant tools more efficiently.\n",
            "\n",
            "3. **Enhancing Clarity in Responses**: Implementing clear and structured tasks allows agents to return meaningful and relevant context from the tools they use. This prioritization helps agents process results better, making adjustments based on high-signal information rather than technical identifiers that may not directly inform their subsequent actions.\n",
            "\n",
            "4. **Facilitating Evaluation and Improvement**: Task decomposition also allows for more effective evaluation of agents’ performance. By analyzing metrics related to individual subtasks (such as the number of tool calls, runtime, and error rates), developers can identify strengths and weaknesses in agent performance and tool efficiency.\n",
            "\n",
            "In summary, task decomposition is essential for enhancing the operational capabilities of agents by simplifying complex processes, improving tool usage, and facilitating systematic evaluation and ongoing enhancement of agent performance.\n",
            "\n",
            "\n",
            "Retrieved 4 source document(s)\n",
            "\n",
            "First source metadata: {'description': 'Writing effective tools for AI agents—using AI agents', 'title': 'Writing effective tools for AI agents—using AI agents \\\\ Anthropic', 'language': 'en', 'source': 'https://www.anthropic.com/engineering/writing-tools-for-agents'}\n"
          ]
        }
      ],
      "source": [
        "query = \"What is task decomposition?\"\n",
        "\n",
        "result = rag_chain_with_sources.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
        ")\n",
        "\n",
        "# Access the final response\n",
        "print(\"Response:\")\n",
        "print(result[\"messages\"][-1].content)\n",
        "\n",
        "# Access the source documents\n",
        "print(f\"\\n\\nRetrieved {len(result.get('context', []))} source document(s)\")\n",
        "if result.get(\"context\"):\n",
        "    print(f\"\\nFirst source metadata: {result['context'][0].metadata}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "**RAG Agents** are best for:\n",
        "- Complex queries requiring multiple searches\n",
        "- When you want the LLM to decide when to search\n",
        "- General-purpose applications\n",
        "\n",
        "**RAG Chains** are best for:\n",
        "- Simple queries with predictable search needs\n",
        "- When speed is critical (single LLM call)\n",
        "- Constrained settings where you always want to search\n",
        "\n",
        "**Next Steps:**\n",
        "- Add conversational memory for multi-turn interactions\n",
        "- Stream tokens for responsive user experiences\n",
        "- Add structured responses\n",
        "- Deploy with LangSmith Deployment\n",
        "- Explore advanced RAG patterns with LangGraph\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
