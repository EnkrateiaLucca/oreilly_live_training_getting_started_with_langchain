{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced LangChain Patterns\n",
    "\n",
    "This notebook covers advanced agent patterns:\n",
    "\n",
    "1. **Structured Output** - Extracting typed data from LLM responses\n",
    "2. **Dynamic Prompts** - Runtime prompt customization via middleware\n",
    "3. **Human-in-the-Loop (HITL)** - Requiring approval before tool execution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Structured Output\n",
    "\n",
    "Often you need structured data from LLMs - not just text. LangChain's `response_format` parameter ensures the output matches a specific schema.\n",
    "\n",
    "## 1.1 Using TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Define the output schema\n",
    "class ContactInfo(TypedDict):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "# Create agent with structured output\n",
    "contact_extractor = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\", \n",
    "    response_format=ContactInfo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contact info from unstructured text\n",
    "recorded_conversation = \"\"\"\n",
    "We talked with John Doe. He works over at Example Corp. \n",
    "His number is five, five, five, one two three, four five six seven. \n",
    "And his email was john at example.com. \n",
    "He wanted to order 50 boxes of supplies.\n",
    "\"\"\"\n",
    "\n",
    "result = contact_extractor.invoke(\n",
    "    {\"messages\": recorded_conversation}\n",
    ")\n",
    "\n",
    "# Access the structured response\n",
    "print(\"Structured output:\")\n",
    "print(result[\"structured_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access individual fields\n",
    "contact = result[\"structured_response\"]\n",
    "print(f\"Name: {contact['name']}\")\n",
    "print(f\"Email: {contact['email']}\")\n",
    "print(f\"Phone: {contact['phone']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Using Pydantic Models\n",
    "\n",
    "Pydantic provides validation and richer type support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class MeetingNote(BaseModel):\n",
    "    title: str = Field(description=\"Brief title for the meeting\")\n",
    "    attendees: List[str] = Field(description=\"List of people who attended\")\n",
    "    action_items: List[str] = Field(description=\"Tasks to be completed\")\n",
    "    next_meeting: Optional[str] = Field(description=\"Date/time of next meeting if mentioned\")\n",
    "    summary: str = Field(description=\"2-3 sentence summary of the meeting\")\n",
    "\n",
    "meeting_summarizer = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    response_format=MeetingNote,\n",
    "    system_prompt=\"Extract structured meeting notes from the transcript.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"\"\"\n",
    "Meeting started at 2pm with Alice, Bob, and Charlie present.\n",
    "\n",
    "Alice: Let's discuss the Q4 roadmap. We need to finalize features by Friday.\n",
    "\n",
    "Bob: I can handle the API documentation. Should be done by Wednesday.\n",
    "\n",
    "Charlie: I'll review the security audit report and send recommendations.\n",
    "\n",
    "Alice: Great. Let's meet again next Monday at 10am to review progress.\n",
    "\n",
    "Meeting ended at 2:30pm.\n",
    "\"\"\"\n",
    "\n",
    "result = meeting_summarizer.invoke({\"messages\": transcript})\n",
    "notes = result[\"structured_response\"]\n",
    "\n",
    "print(f\"Title: {notes.title}\")\n",
    "print(f\"Attendees: {', '.join(notes.attendees)}\")\n",
    "print(f\"\\nAction Items:\")\n",
    "for item in notes.action_items:\n",
    "    print(f\"  - {item}\")\n",
    "print(f\"\\nNext Meeting: {notes.next_meeting}\")\n",
    "print(f\"\\nSummary: {notes.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Complex Nested Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Task(BaseModel):\n",
    "    description: str\n",
    "    assignee: str\n",
    "    priority: Literal[\"high\", \"medium\", \"low\"]\n",
    "    estimated_hours: float\n",
    "\n",
    "class ProjectPlan(BaseModel):\n",
    "    project_name: str\n",
    "    objective: str\n",
    "    tasks: List[Task]\n",
    "    total_estimated_hours: float\n",
    "    risks: List[str]\n",
    "\n",
    "project_planner = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    response_format=ProjectPlan,\n",
    "    system_prompt=\"Create a detailed project plan from the given requirements.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = \"\"\"\n",
    "We need to build a customer feedback dashboard.\n",
    "Team: Sarah (frontend), Mike (backend), Lisa (design)\n",
    "Must be done in 2 weeks.\n",
    "Features: sentiment analysis, charts, export to PDF.\n",
    "\"\"\"\n",
    "\n",
    "result = project_planner.invoke({\"messages\": requirements})\n",
    "plan = result[\"structured_response\"]\n",
    "\n",
    "print(f\"Project: {plan.project_name}\")\n",
    "print(f\"Objective: {plan.objective}\")\n",
    "print(f\"\\nTasks:\")\n",
    "for task in plan.tasks:\n",
    "    print(f\"  [{task.priority.upper()}] {task.description}\")\n",
    "    print(f\"      Assignee: {task.assignee}, Est: {task.estimated_hours}h\")\n",
    "print(f\"\\nTotal Hours: {plan.total_estimated_hours}\")\n",
    "print(f\"\\nRisks:\")\n",
    "for risk in plan.risks:\n",
    "    print(f\"  - {risk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Dynamic Prompts\n",
    "\n",
    "Sometimes you need to customize the system prompt at runtime based on context. LangChain middleware enables this with `@dynamic_prompt`.\n",
    "\n",
    "## 2.1 Role-Based Access Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.runtime import get_runtime\n",
    "from langchain.agents.middleware.types import ModelRequest, dynamic_prompt\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///./assets-resources/Chinook.db\")\n",
    "\n",
    "@dataclass\n",
    "class RuntimeContext:\n",
    "    is_employee: bool  # Access control flag\n",
    "    db: SQLDatabase\n",
    "\n",
    "@tool\n",
    "def execute_sql(query: str) -> str:\n",
    "    \"\"\"Execute a SQLite SELECT query and return results.\"\"\"\n",
    "    runtime = get_runtime(RuntimeContext)\n",
    "    try:\n",
    "        return runtime.context.db.run(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a SQLite analyst.\n",
    "\n",
    "Rules:\n",
    "- Use execute_sql for SELECT queries only.\n",
    "- Limit to 5 rows unless asked otherwise.\n",
    "{table_limits}\n",
    "- If errors occur, revise and retry.\n",
    "\"\"\"\n",
    "\n",
    "@dynamic_prompt\n",
    "def access_controlled_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate prompt based on user's access level.\"\"\"\n",
    "    if not request.runtime.context.is_employee:\n",
    "        # Non-employees have limited table access\n",
    "        table_limits = \"- You can ONLY access: Album, Artist, Genre, Playlist, PlaylistTrack, Track.\"\n",
    "    else:\n",
    "        # Employees have full access\n",
    "        table_limits = \"- You have access to all tables.\"\n",
    "    \n",
    "    return SYSTEM_PROMPT_TEMPLATE.format(table_limits=table_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create agent with dynamic prompt middleware\n",
    "access_controlled_agent = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[execute_sql],\n",
    "    middleware=[access_controlled_prompt],  # <-- Dynamic prompt\n",
    "    context_schema=RuntimeContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-employee: Should be denied access to customer data\n",
    "question = \"What is the most costly purchase by Frank Harris?\"\n",
    "\n",
    "print(\"=== Non-Employee Access ===\")\n",
    "for step in access_controlled_agent.stream(\n",
    "    {\"messages\": question},\n",
    "    context=RuntimeContext(is_employee=False, db=db),\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee: Should have full access\n",
    "print(\"\\n=== Employee Access ===\")\n",
    "for step in access_controlled_agent.stream(\n",
    "    {\"messages\": question},\n",
    "    context=RuntimeContext(is_employee=True, db=db),\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Human-in-the-Loop (HITL)\n",
    "\n",
    "For sensitive operations, you may want human approval before the agent executes tools. The `HumanInTheLoopMiddleware` provides this capability.\n",
    "\n",
    "## 3.1 Basic HITL Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "@dataclass\n",
    "class RuntimeContext:\n",
    "    db: SQLDatabase\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a SQLite analyst.\n",
    "Use execute_sql for queries. Limit to 5 rows.\n",
    "If the database is offline, ask user to try again later.\n",
    "\"\"\"\n",
    "\n",
    "# Create agent with HITL middleware\n",
    "hitl_agent = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[execute_sql],\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    checkpointer=InMemorySaver(),  # Required for HITL\n",
    "    context_schema=RuntimeContext,\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"execute_sql\": {\"allowed_decisions\": [\"approve\", \"reject\"]}\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Handling Interrupts\n",
    "\n",
    "When the agent wants to use a tool, it will pause and wait for approval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"hitl-demo-1\"}}\n",
    "\n",
    "# Start a query that requires tool use\n",
    "result = hitl_agent.invoke(\n",
    "    {\"messages\": \"What are the names of all employees?\"},\n",
    "    config=config,\n",
    "    context=RuntimeContext(db=db)\n",
    ")\n",
    "\n",
    "# Check if we hit an interrupt\n",
    "if \"__interrupt__\" in result:\n",
    "    interrupt_info = result['__interrupt__'][-1].value['action_requests'][-1]\n",
    "    print(\"INTERRUPT DETECTED!\")\n",
    "    print(f\"Tool: {interrupt_info['tool_name']}\")\n",
    "    print(f\"Args: {interrupt_info['args']}\")\n",
    "    print(\"\\nWaiting for human decision...\")\n",
    "else:\n",
    "    print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REJECT the tool call (simulating database being offline)\n",
    "result = hitl_agent.invoke(\n",
    "    Command(\n",
    "        resume={\"decisions\": [{\"type\": \"reject\", \"message\": \"Database is currently offline.\"}]}\n",
    "    ),\n",
    "    config=config,\n",
    "    context=RuntimeContext(db=db),\n",
    ")\n",
    "\n",
    "print(\"After rejection:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Approving Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New conversation with approvals\n",
    "config = {\"configurable\": {\"thread_id\": \"hitl-demo-2\"}}\n",
    "\n",
    "result = hitl_agent.invoke(\n",
    "    {\"messages\": \"What are the names of all employees?\"},\n",
    "    config=config,\n",
    "    context=RuntimeContext(db=db)\n",
    ")\n",
    "\n",
    "# Auto-approve all tool calls until we get a final answer\n",
    "while \"__interrupt__\" in result:\n",
    "    interrupt_info = result['__interrupt__'][-1].value['action_requests'][-1]\n",
    "    print(f\"Approving: {interrupt_info['tool_name']}({interrupt_info['args']})\")\n",
    "    \n",
    "    result = hitl_agent.invoke(\n",
    "        Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "        config=config,\n",
    "        context=RuntimeContext(db=db),\n",
    "    )\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Interactive Approval Function\n",
    "\n",
    "In a real application, you'd prompt the user for approval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_approval(agent, messages, config, context):\n",
    "    \"\"\"Run agent with interactive approval for tool calls.\"\"\"\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": messages},\n",
    "        config=config,\n",
    "        context=context\n",
    "    )\n",
    "    \n",
    "    while \"__interrupt__\" in result:\n",
    "        interrupt_info = result['__interrupt__'][-1].value['action_requests'][-1]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"APPROVAL REQUIRED\")\n",
    "        print(f\"Tool: {interrupt_info['tool_name']}\")\n",
    "        print(f\"Arguments: {interrupt_info['args']}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # In a real app, this would be user input\n",
    "        # For demo, we'll auto-approve\n",
    "        decision = \"approve\"  # or input(\"Approve? (y/n): \").lower() == 'y'\n",
    "        \n",
    "        if decision == \"approve\":\n",
    "            print(\"Approved!\")\n",
    "            result = agent.invoke(\n",
    "                Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "                config=config,\n",
    "                context=context,\n",
    "            )\n",
    "        else:\n",
    "            print(\"Rejected!\")\n",
    "            result = agent.invoke(\n",
    "                Command(resume={\"decisions\": [{\"type\": \"reject\", \"message\": \"User denied\"}]}),\n",
    "                config=config,\n",
    "                context=context,\n",
    "            )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the interactive function\n",
    "config = {\"configurable\": {\"thread_id\": \"hitl-demo-3\"}}\n",
    "result = run_with_approval(\n",
    "    hitl_agent,\n",
    "    \"How many tracks are in each genre?\",\n",
    "    config,\n",
    "    RuntimeContext(db=db)\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Structured Output** - Extracting typed data:\n",
    "   - `TypedDict` for simple schemas\n",
    "   - Pydantic `BaseModel` for validation and complex types\n",
    "   - Nested structures with Lists and Optional fields\n",
    "   - Access via `result[\"structured_response\"]`\n",
    "\n",
    "2. **Dynamic Prompts** - Runtime customization:\n",
    "   - `@dynamic_prompt` decorator\n",
    "   - Access runtime context via `request.runtime.context`\n",
    "   - Role-based access control example\n",
    "\n",
    "3. **Human-in-the-Loop** - Approval workflows:\n",
    "   - `HumanInTheLoopMiddleware` for tool approval\n",
    "   - Handle interrupts with `\"__interrupt__\"` key\n",
    "   - Resume with `Command(resume=...)` \n",
    "   - Approve or reject tool calls\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** [Notebook 4: Modern RAG with LangChain](./2.0-modern-rag-langchain.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
