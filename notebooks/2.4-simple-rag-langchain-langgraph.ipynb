{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://python.langchain.com/docs/tutorials/rag/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "\n",
    "This notebook is an adapted and simplified reproduction of the example in the langchain documentation you can find [here](https://python.langchain.com/docs/tutorials/rag/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet --upgrade langchain-text-splitters langchain-community\n",
    "# %pip install -qU langchain-openai\n",
    "# %pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "_set_env(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cfd57e73-b45c-4a52-b543-79eadd9c4e4d', '47924ec7-8393-4134-ba8a-894926e9d756', 'cc238392-b332-4b3e-8110-74962cf59c59']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph, END\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='91ea85b9-0a31-4630-bdfa-0a5457412ad8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='cc238392-b332-4b3e-8110-74962cf59c59', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='c0864825-b554-4a79-ba60-94ec17f72ac4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='414bef4f-6967-495f-942c-a1c020ec9b99', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.')]\n",
      "\n",
      "\n",
      "Answer: Task decomposition is the process of breaking down complicated tasks into smaller, manageable steps, which can improve problem-solving efficiency. This can be achieved through methods like the Chain of Thought (CoT) prompting technique, where a model is guided to think step by step. Additionally, task decomposition can incorporate human inputs or specific instructions tailored to the task at hand.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='ac7ce4b5-3e8b-4cd8-b595-da845082cac6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 26660}, page_content='Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'), Document(id='e6c3670f-7acb-4587-bd46-6b1303098bdd', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 26660}, page_content='Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:'), Document(id='b1010bdd-501c-444b-b809-556b7f3bb80b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(id='cfd57e73-b45c-4a52-b543-79eadd9c4e4d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'The main elements of an agent include planning, which involves subgoal decomposition for managing complex tasks, and reflection and refinement for learning from past actions. Additionally, memory plays a crucial role, as it enables the agent to retain information and experiences. Together, these components enhance the autonomy and effectiveness of the agent.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What are the main elements of an Agent?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
